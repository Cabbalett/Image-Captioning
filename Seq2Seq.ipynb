{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import torch\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 100\n",
    "pad_id = 0\n",
    "sos_id = 1\n",
    "eos_id = 2\n",
    "\n",
    "src_data = [\n",
    "  [3, 77, 56, 26, 3, 55, 12, 36, 31],\n",
    "  [58, 20, 65, 46, 26, 10, 76, 44],\n",
    "  [58, 17, 8],\n",
    "  [59],\n",
    "  [29, 3, 52, 74, 73, 51, 39, 75, 19],\n",
    "  [41, 55, 77, 21, 52, 92, 97, 69, 54, 14, 93],\n",
    "  [39, 47, 96, 68, 55, 16, 90, 45, 89, 84, 19, 22, 32, 99, 5],\n",
    "  [75, 34, 17, 3, 86, 88],\n",
    "  [63, 39, 5, 35, 67, 56, 68, 89, 55, 66],\n",
    "  [12, 40, 69, 39, 49]\n",
    "]\n",
    "\n",
    "trg_data = [\n",
    "  [75, 13, 22, 77, 89, 21, 13, 86, 95],\n",
    "  [79, 14, 91, 41, 32, 79, 88, 34, 8, 68, 32, 77, 58, 7, 9, 87],\n",
    "  [85, 8, 50, 30],\n",
    "  [47, 30],\n",
    "  [8, 85, 87, 77, 47, 21, 23, 98, 83, 4, 47, 97, 40, 43, 70, 8, 65, 71, 69, 88],\n",
    "  [32, 37, 31, 77, 38, 93, 45, 74, 47, 54, 31, 18],\n",
    "  [37, 14, 49, 24, 93, 37, 54, 51, 39, 84],\n",
    "  [16, 98, 68, 57, 55, 46, 66, 85, 18],\n",
    "  [20, 70, 14, 6, 58, 90, 30, 17, 91, 18, 90],\n",
    "  [37, 93, 98, 13, 45, 28, 89, 72, 70]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "trg_data = [[sos_id]+seq+[eos_id] for seq in trg_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(data):\n",
    "    max_len = len(max(data, key=len))\n",
    "    print(f\"Maximum sequence length: {max_len}\")\n",
    "\n",
    "    valid_lens = []\n",
    "    for i, seq in enumerate(tqdm(data)):\n",
    "        valid_lens.append(len(seq))\n",
    "        if len(seq) < max_len:\n",
    "            data[i] = seq + [pad_id] * (max_len - len(seq))\n",
    "    \n",
    "    return data, valid_lens, max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sequence length: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 28591.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sequence length: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 38944.33it/s]\n"
     ]
    }
   ],
   "source": [
    "src_data, src_lens, src_max_len = padding(src_data)\n",
    "trg_data, trg_lens, trg_max_len = padding(trg_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_batch = torch.LongTensor(src_data)\n",
    "src_batch_lens = torch.LongTensor(src_lens)\n",
    "trg_batch = torch.LongTensor(trg_data)\n",
    "trg_batch_lens = torch.LongTensor(trg_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_batch_lens, sorted_idx = src_batch_lens.sort(descending = True)\n",
    "src_batch = src_batch[sorted_idx]\n",
    "trg_batch = trg_batch[sorted_idx]\n",
    "trg_batch_lens = trg_batch_lens[sorted_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 256\n",
    "hidden_size = 512\n",
    "num_layers = 2\n",
    "num_dirs = 2\n",
    "dropout = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.gru = nn.GRU(\n",
    "            input_size = embedding_size,\n",
    "            hidden_size = hidden_size,\n",
    "            num_layers = num_layers,\n",
    "            bidirectional = True if num_dirs > 1 else False,\n",
    "            dropout = dropout\n",
    "        )\n",
    "        self.linear = nn.Linear(num_dirs*hidden_size, hidden_size)\n",
    "    \n",
    "    def forward(self, batch, batch_lens):\n",
    "        batch_emb = self.embedding(batch)\n",
    "        batch_emb = batch_emb.transpose(0,1)\n",
    "\n",
    "        packed_input = pack_padded_sequence(batch_emb, batch_lens)\n",
    "\n",
    "        h_0 = torch.zeros((num_layers * num_dirs, batch.shape[0], hidden_size))\n",
    "        packed_outputs, h_n = self.gru(packed_input, h_0)\n",
    "        outputs = pad_packed_sequence(packed_outputs)[0]\n",
    "        outputs = torch.tanh(self.linear(outputs))\n",
    "\n",
    "        forward_hidden = h_n[-2, :, :]\n",
    "        backward_hidden = h_n[-1, :, :]\n",
    "        hidden = torch.tanh(self.linear(torch.cat((forward_hidden, backward_hidden), dim=-1))).unsqueeze(0)\n",
    "\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, decoder_hidden, encoder_outputs):\n",
    "        query = decoder_hidden.squeeze(0)\n",
    "        key = encoder_outputs.transpose(0,1)\n",
    "\n",
    "        energy = torch.sum(torch.mul(key, query.unsqueeze(1)), dim=-1)\n",
    "\n",
    "        attn_scores = F.softmax(energy, dim=-1)\n",
    "        attn_values = torch.sum(torch.mul(encoder_outputs.transpose(0,1), attn_scores.unsqueeze(2)), dim=1)\n",
    "\n",
    "        return attn_values, attn_scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_attn = DotAttention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, attention):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.attention = attention\n",
    "        self.rnn = nn.GRU(\n",
    "            embedding_size,\n",
    "            hidden_size\n",
    "        )\n",
    "        self.output_linear = nn.Linear(2*hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, batch, encoder_outputs, hidden):\n",
    "        batch_emb = self.embedding(batch)\n",
    "        batch_emb = batch_emb.unsqueeze(0)\n",
    "\n",
    "        outputs, hidden = self.rnn(batch_emb, hidden)\n",
    "\n",
    "        attn_values, attn_scores = self.attention(hidden, encoder_outputs)\n",
    "        concat_outputs = torch.cat((outputs, attn_values.unsqueeze(0)), dim=-1)\n",
    "\n",
    "        return self.output_linear(concat_outputs).squeeze(0), hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(dot_attn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2seq, self).__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    \n",
    "    def forward(self, src_batch, src_batch_lens, trg_batch, teacher_forcing_prob=0.5):\n",
    "        encoder_outputs, hidden = self.encoder(src_batch, src_batch_lens)\n",
    "\n",
    "        input_ids = trg_batch[:,0]\n",
    "        batch_size = src_batch.shape[0]\n",
    "        outputs = torch.zeros(trg_max_len, batch_size, vocab_size)\n",
    "\n",
    "        for t in range(1, trg_max_len):\n",
    "            decoder_outputs, hidden = self.decoder(input_ids, encoder_outputs, hidden)\n",
    "\n",
    "            outputs[t] = decoder_outputs\n",
    "            _, top_ids = torch.max(decoder_outputs, dim=-1)\n",
    "\n",
    "            input_ids = trg_batch[:,t] if random.random() > teacher_forcing_prob else top_ids\n",
    "            \n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq = Seq2seq(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.0131,  0.0897,  0.0474,  ...,  0.0270,  0.1594, -0.0348],\n",
      "         [-0.0163,  0.0730,  0.0749,  ...,  0.0136,  0.1549,  0.0019],\n",
      "         [ 0.0076,  0.1346,  0.0858,  ...,  0.0441,  0.1306, -0.0108],\n",
      "         ...,\n",
      "         [-0.0280,  0.0961,  0.0580,  ...,  0.0255,  0.2035, -0.0104],\n",
      "         [-0.0219,  0.1460,  0.0539,  ...,  0.0374,  0.1733, -0.0457],\n",
      "         [-0.0228,  0.1014,  0.0735,  ...,  0.0275,  0.1726, -0.0381]],\n",
      "\n",
      "        [[ 0.0907,  0.0176,  0.0850,  ...,  0.1600, -0.0279, -0.0637],\n",
      "         [ 0.0764,  0.0901,  0.0688,  ...,  0.0195,  0.0752, -0.0084],\n",
      "         [ 0.0941,  0.1593,  0.1366,  ...,  0.1006,  0.0660,  0.0127],\n",
      "         ...,\n",
      "         [ 0.0722,  0.0269,  0.0941,  ...,  0.1526,  0.0153, -0.0485],\n",
      "         [-0.0879, -0.0387,  0.0408,  ...,  0.0072,  0.1974, -0.0022],\n",
      "         [ 0.0035,  0.0666,  0.1691,  ...,  0.1835,  0.1796,  0.0525]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.2259,  0.0648, -0.1291,  ...,  0.1969, -0.0685,  0.0235],\n",
      "         [ 0.1207,  0.0578, -0.0341,  ...,  0.1389, -0.0624,  0.1503],\n",
      "         [ 0.1377,  0.1036,  0.0043,  ...,  0.1799, -0.0444,  0.1102],\n",
      "         ...,\n",
      "         [ 0.2153,  0.0763, -0.1273,  ...,  0.1752, -0.0402,  0.0287],\n",
      "         [ 0.1564,  0.1076, -0.0098,  ...,  0.2030, -0.0311,  0.1382],\n",
      "         [ 0.1550,  0.0814,  0.0041,  ...,  0.1931, -0.0314,  0.1356]],\n",
      "\n",
      "        [[ 0.1689,  0.0037, -0.1449,  ...,  0.1656, -0.1226,  0.0398],\n",
      "         [ 0.1387, -0.0204, -0.1210,  ...,  0.1319, -0.1493,  0.1263],\n",
      "         [ 0.1490,  0.0225, -0.0918,  ...,  0.1623, -0.1377,  0.0940],\n",
      "         ...,\n",
      "         [ 0.1568,  0.0152, -0.1437,  ...,  0.1467, -0.0920,  0.0455],\n",
      "         [ 0.1655,  0.0259, -0.1128,  ...,  0.1788, -0.1157,  0.1108],\n",
      "         [ 0.1570,  0.0061, -0.1010,  ...,  0.1700, -0.1121,  0.1091]],\n",
      "\n",
      "        [[ 0.1437,  0.1156, -0.0007,  ...,  0.2125, -0.0277,  0.1165],\n",
      "         [ 0.2276,  0.0287,  0.0030,  ...,  0.1775, -0.1629,  0.0566],\n",
      "         [ 0.2394,  0.0658,  0.0204,  ...,  0.2043, -0.1521,  0.0341],\n",
      "         ...,\n",
      "         [ 0.1326,  0.1195,  0.0038,  ...,  0.1927,  0.0136,  0.1220],\n",
      "         [ 0.2482,  0.0662,  0.0058,  ...,  0.2077, -0.1343,  0.0404],\n",
      "         [ 0.2372,  0.0502,  0.0146,  ...,  0.2026, -0.1318,  0.0413]]],\n",
      "       grad_fn=<CopySlices>)\n",
      "torch.Size([22, 10, 100])\n"
     ]
    }
   ],
   "source": [
    "outputs = seq2seq(src_batch, src_batch_lens, trg_batch)\n",
    "\n",
    "print(outputs)\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6fdbf7a2e76085077dc0a394c32ded7d379293957f185ae5c02d6972f7a65f33"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
